{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "from plotly.offline import init_notebook_mode\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = 'data/small/'\n",
    "GROUND_TRUTH_PATH = DATA_DIR + 'pan20-authorship-verification-training-small-truth.jsonl'\n",
    "DATA_PATH = DATA_DIR + 'pan20-authorship-verification-training-small.jsonl'\n",
    "TEMP_DATA_PATH = 'temp_data/small_model_training_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id_to_authors = {}\n",
    "with open(GROUND_TRUTH_PATH, 'r') as f:\n",
    "    for l in f:\n",
    "        d = json.loads(l)\n",
    "        id_to_authors[d['id']] = d['authors']\n",
    "\n",
    "data = []\n",
    "with open(DATA_PATH, 'r') as f:\n",
    "    for l in f:\n",
    "        d = json.loads(l)\n",
    "        data.append([\n",
    "            d['id'],\n",
    "            d['fandoms'][0],\n",
    "            d['fandoms'][1],\n",
    "            id_to_authors[d['id']][0],\n",
    "            id_to_authors[d['id']][1],\n",
    "            id_to_authors[d['id']][0] == id_to_authors[d['id']][1],\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=data, columns=['index', 'fandom1', 'fandom2', 'author1', 'author2', 'label']).set_index('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of training records from each same-author author\n",
    "t = df.loc[df['label']==True].groupby('author1')['author1'].count()\n",
    "go.Figure().add_trace(go.Histogram(x=t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of documents from different-author authors\n",
    "t1 = df.loc[df['label']==False]['author1'].values\n",
    "t2 = df.loc[df['label']==False]['author2'].values\n",
    "\n",
    "different_author_authors, counts = np.unique(np.concatenate([t1, t2]), return_counts=True)\n",
    "go.Figure().add_trace(go.Histogram(x=counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "same_author_authors = df.loc[df['label']==True]['author1'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('# Same-author authors: ', len(same_author_authors))\n",
    "print('# diff-author authors:', len(different_author_authors))\n",
    "print('Intersection:', len(np.intersect1d(same_author_authors, different_author_authors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "author_to_id = defaultdict(set)\n",
    "for i, r in df.iterrows():\n",
    "    author_to_id[r['author1']].add(i)\n",
    "    author_to_id[r['author2']].add(i)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_associated_authors_and_probs(author, author_to_id, id_to_authors):\n",
    "    authors = set()\n",
    "    idxs = set()\n",
    "    _get_associated_authors_and_probs(authors, idxs, author, author_to_id, id_to_authors)\n",
    "    return list(authors), list(idxs)\n",
    "    \n",
    "\n",
    "def _get_associated_authors_and_probs(ret_authors, ret_idxs, author, author_to_id, id_to_authors):\n",
    "    if author in ret_authors:\n",
    "        return\n",
    "    ret_authors.add(author)\n",
    "    for idx in author_to_id[author]:\n",
    "        ret_idxs.add(idx)\n",
    "        for a in id_to_authors[idx]:\n",
    "            if a not in ret_authors:\n",
    "                _get_associated_authors_and_probs(ret_authors, ret_idxs, a, author_to_id, id_to_authors)\n",
    "                ret_authors.add(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_authors = set()\n",
    "test_authors = set()\n",
    "train_ids = set()\n",
    "test_ids = set()\n",
    "\n",
    "for a in np.concatenate([same_author_authors, different_author_authors]):\n",
    "    if np.random.rand() < 0.75:\n",
    "        if a in test_authors:\n",
    "            continue\n",
    "        train_authors.add(a)\n",
    "        authors, probs = get_associated_authors_and_probs(a, author_to_id, id_to_authors)\n",
    "        train_authors.update(authors)\n",
    "        train_ids.update(probs)\n",
    "\n",
    "    else:\n",
    "        if a in train_authors:\n",
    "            continue\n",
    "        test_authors.add(a)\n",
    "        authors, probs = get_associated_authors_and_probs(a, author_to_id, id_to_authors)\n",
    "        test_authors.update(authors)\n",
    "        test_ids.update(probs)\n",
    "\n",
    "train_a = np.unique(np.concatenate([df.loc[list(train_ids)]['author1'].values, df.loc[list(train_ids)]['author2'].values]))\n",
    "test_a = np.unique(np.concatenate([df.loc[list(test_ids)]['author1'].values, df.loc[list(test_ids)]['author2'].values]))\n",
    "assert len(np.intersect1d(train_a, test_a)) == 0, 'Train and test authors are mixed!'\n",
    "\n",
    "print('Fraction of train authors:', len(train_ids)/(len(train_ids) + len(test_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = df.loc[list(train_ids)]\n",
    "test_df = df.loc[list(test_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(TEMP_DATA_PATH + 'dataset_partition.p', 'wb') as f:\n",
    "    pickle.dump((train_ids, test_ids, train_authors, test_authors), f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
